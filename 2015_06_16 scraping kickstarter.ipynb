{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# last one - music\n",
    "# use the same primary key as my other\n",
    "# columns - project and creator pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint\n",
    "import pymysql as mdb\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con = mdb.connect('localhost','root','hobbes','kickstarter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('information_schema',)\n",
      "('kickscrape',)\n",
      "('kickstarter',)\n",
      "('mysql',)\n",
      "('performance_schema',)\n",
      "('test',)\n",
      "('testdb',)\n",
      "('world_innodb',)\n"
     ]
    }
   ],
   "source": [
    "with con:\n",
    "    \n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"SHOW DATABASES\")\n",
    "    \n",
    "    rows = cur.fetchall()\n",
    "    for row in rows:\n",
    "        print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with con:\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"SELECT Id, Creator_url, URL FROM Project_info \\\n",
    "                WHERE Category_slug LIKE 'music%'\")\n",
    "    id_urls = cur.fetchall()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_urls = np.asarray(id_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34326, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(id_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19011\n",
      "19111\n",
      "19211\n",
      "19311\n",
      "19411\n",
      "19511\n",
      "19611\n",
      "19711\n",
      "19811\n",
      "19911\n",
      "20011\n",
      "20111\n",
      "20211\n",
      "20311\n",
      "20411\n",
      "20511\n",
      "20611\n",
      "20711\n",
      "20811\n",
      "20911\n",
      "21011\n",
      "21111\n",
      "21211\n",
      "21311\n",
      "21411\n",
      "21511\n",
      "21611\n",
      "21711\n",
      "21811\n",
      "21911\n",
      "22011\n",
      "22111\n",
      "22211\n",
      "22311\n",
      "22411\n",
      "22511\n",
      "22611\n",
      "22711\n",
      "22811\n",
      "22911\n",
      "23011\n",
      "23111\n",
      "23211\n",
      "23311\n",
      "23411\n",
      "23511\n",
      "23611\n",
      "23711\n",
      "23811\n",
      "23911\n",
      "24011\n",
      "24111\n",
      "24211\n",
      "24311\n",
      "24411\n",
      "24511\n",
      "24611\n",
      "24711\n",
      "24811\n",
      "24911\n",
      "25011\n",
      "25111\n",
      "25211\n",
      "25311\n",
      "25411\n",
      "25511\n",
      "25611\n",
      "25711\n",
      "25811\n",
      "25911\n",
      "26011\n",
      "26111\n",
      "26211\n",
      "26311\n",
      "26411\n",
      "26511\n",
      "26611\n",
      "26711\n",
      "26811\n",
      "26911\n",
      "27011\n",
      "27111\n",
      "27211\n",
      "27311\n",
      "27411\n",
      "27511\n",
      "27611\n",
      "27711\n",
      "27811\n",
      "27911\n",
      "28011\n",
      "28111\n",
      "28211\n",
      "28311\n",
      "28411\n",
      "28511\n",
      "28611\n",
      "28711\n",
      "28811\n",
      "28911\n",
      "29011\n",
      "29111\n",
      "29211\n",
      "29311\n",
      "29411\n",
      "29511\n",
      "29611\n",
      "29711\n",
      "29811\n",
      "29911\n",
      "30011\n",
      "30111\n",
      "30211\n",
      "30311\n",
      "30411\n",
      "30511\n",
      "30611\n",
      "30711\n",
      "30811\n",
      "30911\n",
      "31011\n",
      "31111\n",
      "31211\n",
      "31311\n",
      "31411\n",
      "31511\n",
      "31611\n",
      "31711\n",
      "31811\n",
      "31911\n",
      "32011\n",
      "32111\n",
      "32211\n",
      "32311\n",
      "32411\n",
      "32511\n",
      "32611\n",
      "32711\n",
      "32811\n",
      "32911\n",
      "33011\n",
      "33111\n",
      "33211\n",
      "33311\n",
      "33411\n",
      "33511\n",
      "33611\n",
      "33711\n",
      "33811\n",
      "33911\n",
      "34011\n",
      "34111\n",
      "34211\n",
      "34311\n"
     ]
    }
   ],
   "source": [
    "with con:\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    for i,id_url in enumerate(id_urls[19011:]): \n",
    "        #print i\n",
    "        if not i%100:\n",
    "            print i+19011 \n",
    "            \n",
    "        primary_key, creator_url, project_url = id_url\n",
    "        project_url = project_url.replace('?ref=category','/description')\n",
    "    \n",
    "        project_request = requests.get(project_url)\n",
    "        creator_request = requests.get(creator_url)\n",
    "        project_raw = unidecode(project_request.text)\n",
    "        creator_raw = unidecode(creator_request.text)\n",
    "        \n",
    "        cur.execute(\"INSERT INTO Scraped_pages () VALUES(%s,%s,%s)\",\\\n",
    "            [primary_key,project_raw,creator_raw])\n",
    "        \n",
    "        con.commit()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13907\n"
     ]
    }
   ],
   "source": [
    "print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Scrape a missed page.\n",
    "with con:\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    for i,id_url in enumerate(id_urls): \n",
    "        #print i\n",
    "        if not i%200:\n",
    "            print i\n",
    "            \n",
    "        primary_key, creator_url, project_url = id_url\n",
    "        project_url = project_url.replace('?ref=category','/description')\n",
    "    \n",
    "        project_request = requests.get(project_url)\n",
    "        creator_request = requests.get(creator_url)\n",
    "        project_raw = unidecode(project_request.text)\n",
    "        creator_raw = unidecode(creator_request.text)\n",
    "        \n",
    "        #cur.execute(\"UPDATE Scraped_pages SET Project_html = %s,\\\n",
    "        #    Creator_html = %s WHERE Id = %s\",(project_raw,creator_raw,14732))\n",
    "        \n",
    "        \n",
    "        con.commit()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14732\n"
     ]
    }
   ],
   "source": [
    "print primary_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with con:\n",
    "    cur = con.cursor()\n",
    "    cur.execute(\"INSERT INTO Scraped_pages () VALUES(%s,%s,%s)\",\\\n",
    "            [primary_key,project_raw,creator_raw])\n",
    "    con.commit()\n",
    "    cur.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
